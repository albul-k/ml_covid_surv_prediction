{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.utils import resample\r\n",
    "\r\n",
    "from supervised.automl import AutoML\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df_init = pd.read_csv('data_v3.csv', sep=';')\r\n",
    "df_init.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Id       Number  Result  Feature_1  Feature_2  Feature_3  Feature_4  \\\n",
       "0   1  10359/C2020       2          2         56         12          1   \n",
       "1   2  10346/C2020       2          2         69         19          1   \n",
       "2   3  10311/C2020       2          1         66          8          1   \n",
       "3   4  10292/C2020       2          2         62         16          1   \n",
       "4   5  10283/C2020       2          2         67         30          1   \n",
       "\n",
       "   Feature_5  Feature_6  Feature_106  ...  Feature_99  Feature_100  \\\n",
       "0        7.0          4            2  ...         0.0          0.0   \n",
       "1        6.0          4            2  ...         0.0          0.0   \n",
       "2        4.0          4            2  ...         0.0          0.0   \n",
       "3        NaN          3            2  ...         0.0          0.0   \n",
       "4        NaN          4            2  ...         0.0          0.0   \n",
       "\n",
       "   Feature_111  Feature_1122  Feature_112  Feature_113  Feature_114  \\\n",
       "0            1             0            1            1          1.0   \n",
       "1            1             0            1            1          1.0   \n",
       "2            1             0            1            1          1.0   \n",
       "3            1             0            1            1          0.0   \n",
       "4            1             0            1            1          1.0   \n",
       "\n",
       "   Feature_115  Feature_116  Feature_117  \n",
       "0            1            1            0  \n",
       "1            0            1            1  \n",
       "2            0            1            0  \n",
       "3            0            1            1  \n",
       "4            0            1            0  \n",
       "\n",
       "[5 rows x 117 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Number</th>\n",
       "      <th>Result</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_106</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_99</th>\n",
       "      <th>Feature_100</th>\n",
       "      <th>Feature_111</th>\n",
       "      <th>Feature_1122</th>\n",
       "      <th>Feature_112</th>\n",
       "      <th>Feature_113</th>\n",
       "      <th>Feature_114</th>\n",
       "      <th>Feature_115</th>\n",
       "      <th>Feature_116</th>\n",
       "      <th>Feature_117</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10359/C2020</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10346/C2020</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10311/C2020</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10292/C2020</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10283/C2020</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 117 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "target_feature = 'Result'\r\n",
    "\r\n",
    "useless_features = ['Id', 'Number', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6', 'Feature_17', 'Feature_18', 'Feature_23', \r\n",
    "                    'Feature_29', 'Feature_30', 'Feature_32','Feature_33', 'Feature_34',\r\n",
    "                    'Feature_35', 'Feature_54', 'Feature_65', 'Feature_94', 'Feature_101', 'Feature_108','Feature_111', \r\n",
    "                    'Feature_112','Feature_113', 'Feature_114','Feature_115', 'Feature_116', 'Feature_117']\r\n",
    "features_to_drop = [target_feature] + useless_features\r\n",
    "features = df_init.columns.drop(features_to_drop).tolist()\r\n",
    "\r\n",
    "# features = ['Feature_47', 'Feature_106', 'Feature_41', 'Feature_2', 'Feature_40', 'Feature_9', 'Feature_73', 'Feature_51', 'Feature_31', 'Feature_48', 'Feature_71', 'Feature_70', 'Feature_59', 'Feature_39', 'Feature_84']\r\n",
    "\r\n",
    "df_ = df_init[[target_feature] + features]\r\n",
    "\r\n",
    "num_features = ['Feature_2', 'Feature_3', 'Feature_33', 'Feature_34', 'Feature_36', 'Feature_37', 'Feature_38', 'Feature_39', 'Feature_40', \r\n",
    "                'Feature_41', 'Feature_42', 'Feature_43', 'Feature_44', 'Feature_45', 'Feature_46', 'Feature_47', \r\n",
    "                'Feature_48', 'Feature_49', 'Feature_50', 'Feature_51', 'Feature_53', 'Feature_55', 'Feature_57', \r\n",
    "                'Feature_58', 'Feature_59', 'Feature_64', 'Feature_70', 'Feature_71', 'Feature_72', 'Feature_73']\r\n",
    "\r\n",
    "special_features = ['Feature_17', 'Feature_18', 'Feature_23', 'Feature_74', 'Feature_75', 'Feature_76', 'Feature_77', \r\n",
    "                    'Feature_78', 'Feature_79', 'Feature_80', 'Feature_81', 'Feature_82', 'Feature_83', 'Feature_84', \r\n",
    "                    'Feature_85', 'Feature_86', 'Feature_87', 'Feature_88', 'Feature_89', 'Feature_90', 'Feature_91', \r\n",
    "                    'Feature_92', 'Feature_93', 'Feature_94', 'Feature_95', 'Feature_96', 'Feature_97', 'Feature_98', \r\n",
    "                    'Feature_99', 'Feature_100']\r\n",
    "\r\n",
    "for col in special_features:\r\n",
    "    if col in df_.columns:\r\n",
    "        df_[col].fillna(0, inplace=True)\r\n",
    "\r\n",
    "cat_features = []\r\n",
    "for col in df_.drop(target_feature, axis=1).columns:\r\n",
    "    if col in num_features:\r\n",
    "        df_[col].fillna(df_[col].median(), inplace=True)\r\n",
    "        df_[col] = df_[col].astype('float64')\r\n",
    "    else:\r\n",
    "        cat_features.append(col)\r\n",
    "        df_[col].fillna(-1, inplace=True)\r\n",
    "        df_[col] = df_[col].astype('int64')\r\n",
    "\r\n",
    "# Result=0 - alive, Result=1 died\r\n",
    "df_.loc[df_[target_feature] == 1, target_feature] = 0\r\n",
    "df_.loc[df_[target_feature] == 2, target_feature] = 1\r\n",
    "\r\n",
    "df_train, df_test = train_test_split(\r\n",
    "    df_,\r\n",
    "    shuffle=True,\r\n",
    "    test_size=0.25,\r\n",
    "    random_state=0,\r\n",
    "    stratify=df_[target_feature],\r\n",
    ")\r\n",
    "\r\n",
    "# Separate majority and minority classes\r\n",
    "df_majority = df_train[df_train[target_feature] == 1]\r\n",
    "df_minority = df_train[df_train[target_feature] == 0]\r\n",
    "\r\n",
    "# Upsample majority class\r\n",
    "df_majority_upsampled = resample(\r\n",
    "    df_majority,\r\n",
    "    replace=True,\r\n",
    "    n_samples=100,\r\n",
    "    random_state=0,\r\n",
    ")\r\n",
    "# Upsample minority class\r\n",
    "df_minority_upsampled = resample(\r\n",
    "    df_minority,\r\n",
    "    replace=True,\r\n",
    "    n_samples=100,\r\n",
    "    random_state=0,\r\n",
    ")\r\n",
    "# Combine minority class with downsampled majority class\r\n",
    "df_train_sampled = pd.concat([df_majority_upsampled, df_minority_upsampled])\r\n",
    "\r\n",
    "X_train = df_train_sampled[features]\r\n",
    "y_train = df_train_sampled[target_feature]\r\n",
    "\r\n",
    "X_test = df_test[features]\r\n",
    "y_test = df_test[target_feature]\r\n",
    "\r\n",
    "automl = AutoML(\r\n",
    "    results_path='reports/automl-ver_2/',\r\n",
    "    mode='Perform',\r\n",
    "    ml_task='binary_classification',\r\n",
    "    algorithms=['Xgboost'],\r\n",
    ")\r\n",
    "automl.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AutoML directory: reports/automl-ver_2/\n",
      "The task is binary_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['Xgboost']\n",
      "AutoML will ensemble availabe models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 1 model\n",
      "1_Default_Xgboost logloss 0.332851 trained in 25.04 seconds (1-sample predict time 0.204 seconds)\n",
      "* Step not_so_random will try to check up to 4 models\n",
      "2_Xgboost logloss 0.448854 trained in 40.06 seconds (1-sample predict time 0.402 seconds)\n",
      "3_Xgboost logloss 0.331957 trained in 34.99 seconds (1-sample predict time 0.492 seconds)\n",
      "4_Xgboost logloss 0.693147 trained in 21.81 seconds (1-sample predict time 0.38 seconds)\n",
      "5_Xgboost logloss 0.693147 trained in 22.17 seconds (1-sample predict time 0.3231 seconds)\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 10\n",
      "Add Golden Feature: Feature_31_sum_Feature_106\n",
      "Add Golden Feature: Feature_90_sum_Feature_106\n",
      "Add Golden Feature: Feature_109_multiply_Feature_106\n",
      "Add Golden Feature: Feature_109_sum_Feature_106\n",
      "Add Golden Feature: Feature_62_multiply_Feature_106\n",
      "Add Golden Feature: Feature_62_sum_Feature_106\n",
      "Add Golden Feature: Feature_79_sum_Feature_106\n",
      "Add Golden Feature: Feature_31_diff_Feature_1122\n",
      "Add Golden Feature: Feature_106_diff_Feature_66\n",
      "Add Golden Feature: Feature_92_sum_Feature_106\n",
      "Created 10 Golden Features in 36.21 seconds.\n",
      "3_Xgboost_GoldenFeatures logloss 0.332928 trained in 66.52 seconds (1-sample predict time 0.3525 seconds)\n",
      "1_Default_Xgboost_GoldenFeatures logloss 0.326989 trained in 28.34 seconds (1-sample predict time 0.3199 seconds)\n",
      "2_Xgboost_GoldenFeatures logloss 0.436148 trained in 20.9 seconds (1-sample predict time 0.3264 seconds)\n",
      "* Step insert_random_feature will try to check up to 1 model\n",
      "1_Default_Xgboost_GoldenFeatures_RandomFeature logloss 0.343393 trained in 20.77 seconds (1-sample predict time 0.3088 seconds)\n",
      "Drop features ['Feature_57', 'random_feature', 'Feature_53', 'Feature_44', 'Feature_84', 'Feature_63', 'Feature_37', 'Feature_86', 'Feature_39', 'Feature_7', 'Feature_60', 'Feature_90', 'Feature_67', 'Feature_42', 'Feature_24', 'Feature_74', 'Feature_76', 'Feature_15', 'Feature_66', 'Feature_52', 'Feature_1', 'Feature_78', 'Feature_93', 'Feature_92', 'Feature_50', 'Feature_107', 'Feature_109_sum_Feature_106', 'Feature_88', 'Feature_98', 'Feature_62_multiply_Feature_106', 'Feature_95', 'Feature_1122', 'Feature_99', 'Feature_89', 'Feature_27', 'Feature_96', 'Feature_61', 'Feature_110', 'Feature_25', 'Feature_97', 'Feature_26', 'Feature_87', 'Feature_109', 'Feature_69', 'Feature_77', 'Feature_79', 'Feature_80', 'Feature_22', 'Feature_82', 'Feature_83', 'Feature_91', 'Feature_85', 'Feature_81', 'Feature_68', 'Feature_10', 'Feature_21', 'Feature_16', 'Feature_14', 'Feature_13', 'Feature_12', 'Feature_62_sum_Feature_106', 'Feature_31_diff_Feature_1122', 'Feature_56', 'Feature_58', 'Feature_90_sum_Feature_106', 'Feature_106', 'Feature_79_sum_Feature_106', 'Feature_75', 'Feature_11', 'Feature_46', 'Feature_48', 'Feature_55', 'Feature_45', 'Feature_38', 'Feature_109_multiply_Feature_106', 'Feature_92_sum_Feature_106', 'Feature_62', 'Feature_31_sum_Feature_106', 'Feature_43', 'Feature_64', 'Feature_49']\n",
      "* Step features_selection will try to check up to 1 model\n",
      "1_Default_Xgboost_GoldenFeatures_SelectedFeatures logloss 0.287954 trained in 9.03 seconds (1-sample predict time 0.2039 seconds)\n",
      "* Step hill_climbing_1 will try to check up to 4 models\n",
      "6_Xgboost_GoldenFeatures_SelectedFeatures logloss 0.274481 trained in 9.47 seconds (1-sample predict time 0.2049 seconds)\n",
      "7_Xgboost_GoldenFeatures_SelectedFeatures logloss 0.28382 trained in 12.38 seconds (1-sample predict time 0.3118 seconds)\n",
      "8_Xgboost_GoldenFeatures logloss 0.326846 trained in 33.59 seconds (1-sample predict time 0.3615 seconds)\n",
      "9_Xgboost_GoldenFeatures logloss 0.324927 trained in 40.17 seconds (1-sample predict time 0.6825 seconds)\n",
      "* Step hill_climbing_2 will try to check up to 2 models\n",
      "10_Xgboost_GoldenFeatures_SelectedFeatures logloss 0.292463 trained in 11.62 seconds (1-sample predict time 0.1758 seconds)\n",
      "11_Xgboost_GoldenFeatures_SelectedFeatures logloss 0.289011 trained in 9.37 seconds (1-sample predict time 0.1667 seconds)\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble logloss 0.274481 trained in 1.87 seconds (1-sample predict time 0.1828 seconds)\n",
      "AutoML fit time: 485.37 seconds\n",
      "AutoML best model: 6_Xgboost_GoldenFeatures_SelectedFeatures\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AutoML(algorithms=['Xgboost'], ml_task='binary_classification', mode='Perform',\n",
       "       results_path='reports/automl-ver_2/')"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\r\n",
    "\r\n",
    "y_test_pred = automl.predict(X_test)\r\n",
    "\r\n",
    "print(f'Accuracy: {round(accuracy_score(y_test, y_test_pred), 2)}')\r\n",
    "print(f'F1 Score: {round(f1_score(y_test, y_test_pred), 2)}')\r\n",
    "print(f'\\nClassification report: \\n{classification_report(y_test, y_test_pred)}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.7\n",
      "F1 Score: 0.69\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        31\n",
      "           1       0.71      0.67      0.69        30\n",
      "\n",
      "    accuracy                           0.70        61\n",
      "   macro avg       0.71      0.70      0.70        61\n",
      "weighted avg       0.71      0.70      0.70        61\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit"
  },
  "interpreter": {
   "hash": "ca35beca1e73f0e8e48de5d26c91c8a581bc78491f6978c6ebd776970508bb03"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}