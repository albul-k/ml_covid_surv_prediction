{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Id  Result  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  \\\n",
       "0   1       2          2         56         12          1        7.0   \n",
       "1   2       2          2         69         19          1        6.0   \n",
       "2   3       2          1         66          8          1        4.0   \n",
       "3   4       2          2         62         16          1        NaN   \n",
       "4   5       2          2         67         30          1        NaN   \n",
       "\n",
       "   Feature_6  Feature_7  Feature_8  ...  Feature_109  Feature_110  \\\n",
       "0          4          0        1.0  ...          1.0          0.0   \n",
       "1          4          0        1.0  ...          1.0          0.0   \n",
       "2          4          0        1.0  ...          1.0          0.0   \n",
       "3          3          0        1.0  ...          1.0          0.0   \n",
       "4          4          0        1.0  ...          1.0          0.0   \n",
       "\n",
       "   Feature_111  Feature_112  Feature_113  Feature_114  Feature_115  \\\n",
       "0            1            0            1            1            1   \n",
       "1            1            0            1            1            1   \n",
       "2            1            0            1            1            1   \n",
       "3            1            0            1            1            0   \n",
       "4            1            0            1            1            1   \n",
       "\n",
       "   Feature_116  Feature_117  Feature_118  \n",
       "0            1            1            0  \n",
       "1            0            1            1  \n",
       "2            0            1            0  \n",
       "3            0            1            1  \n",
       "4            0            1            0  \n",
       "\n",
       "[5 rows x 116 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Result</th>\n      <th>Feature_1</th>\n      <th>Feature_2</th>\n      <th>Feature_3</th>\n      <th>Feature_4</th>\n      <th>Feature_5</th>\n      <th>Feature_6</th>\n      <th>Feature_7</th>\n      <th>Feature_8</th>\n      <th>...</th>\n      <th>Feature_109</th>\n      <th>Feature_110</th>\n      <th>Feature_111</th>\n      <th>Feature_112</th>\n      <th>Feature_113</th>\n      <th>Feature_114</th>\n      <th>Feature_115</th>\n      <th>Feature_116</th>\n      <th>Feature_117</th>\n      <th>Feature_118</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>56</td>\n      <td>12</td>\n      <td>1</td>\n      <td>7.0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>69</td>\n      <td>19</td>\n      <td>1</td>\n      <td>6.0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>66</td>\n      <td>8</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>62</td>\n      <td>16</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2</td>\n      <td>2</td>\n      <td>67</td>\n      <td>30</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 116 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df_init = pd.read_csv('data.csv', sep=';')\n",
    "df_init.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df, trash_features = [], drop_susp_features = True):\n",
    "\n",
    "    df_ = df.copy()\n",
    "\n",
    "    target_feature = 'Result'\n",
    "    golden_features = ['Feature_3', 'Feature_4', 'Feature_35', 'Feature_17', 'Feature_18', 'Feature_22', 'Feature_23', 'Feature_54', 'Feature_94', 'Feature_108']\n",
    "    susp_features = ['Feature_29', 'Feature_30', 'Feature_32', 'Feature_101'] if drop_susp_features else []\n",
    "    all_features = df_.columns.drop([target_feature] + golden_features + susp_features + trash_features + ['Id']).tolist()\n",
    "\n",
    "    df_ = df_[[target_feature] + all_features]\n",
    "\n",
    "    num_features = ['Feature_39', 'Feature_40', 'Feature_41', 'Feature_42', 'Feature_43', 'Feature_44', 'Feature_45', 'Feature_46',\n",
    "                'Feature_47', 'Feature_48', 'Feature_49', 'Feature_50', 'Feature_51', 'Feature_53', 'Feature_55', 'Feature_57', \n",
    "                'Feature_58', 'Feature_59', 'Feature_64', 'Feature_70', 'Feature_71', 'Feature_72', 'Feature_73']\n",
    "    \n",
    "    special_features = ['Feature_17', 'Feature_18', 'Feature_23', 'Feature_74', 'Feature_75', 'Feature_76', 'Feature_77', 'Feature_78', \n",
    "                    'Feature_79', 'Feature_80', 'Feature_81', 'Feature_82', 'Feature_83', 'Feature_84', 'Feature_85', 'Feature_86', 'Feature_87', \n",
    "                    'Feature_88', 'Feature_89', 'Feature_90', 'Feature_91', 'Feature_92', 'Feature_93', 'Feature_94', 'Feature_95', 'Feature_96', \n",
    "                    'Feature_97', 'Feature_98', 'Feature_99', 'Feature_100']\n",
    "    for col in special_features:\n",
    "        if col in df_.columns:\n",
    "            df_[col].fillna(0, inplace=True)\n",
    "\n",
    "    cat_features = []\n",
    "    for col in df_.drop(target_feature, axis=1).columns:\n",
    "        if col in num_features:\n",
    "            df_[col].fillna(df_[col].median(), inplace=True)\n",
    "            df_[col] = df_[col].astype('float64')\n",
    "        else:\n",
    "            cat_features.append(col)\n",
    "\n",
    "            df_[col].fillna(-1, inplace=True)\n",
    "            df_[col] = df_[col].astype('int64')\n",
    "    \n",
    "    # Result=0 - alive, Result=1 died\n",
    "    df_.loc[df_[target_feature] == 1, target_feature] = 0\n",
    "    df_.loc[df_[target_feature] == 2, target_feature] = 1\n",
    "\n",
    "    X = df_[all_features]\n",
    "    y = df_[target_feature]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        shuffle=True,\n",
    "        test_size=0.25,\n",
    "        random_state=0,\n",
    "        stratify=y,\n",
    "    )\n",
    "\n",
    "    train_pool = Pool(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cat_features=cat_features\n",
    "    )\n",
    "\n",
    "    params_frozen = {\n",
    "        'eval_metric': 'Accuracy',\n",
    "        'early_stopping_rounds': 50,\n",
    "    }\n",
    "\n",
    "    params_grid = {\n",
    "        'depth': [4, 6, 8, 10],\n",
    "        'learning_rate': [0.03, 0.1, 0.3, 0.5],\n",
    "        'iterations': [100, 200, 400, 600, 800, 1000, 1200],\n",
    "        'l2_leaf_reg': [2, 2.5, 3, 3.5, 4],\n",
    "        'bagging_temperature': [1, 1.5, 2, 2.5],\n",
    "    }\n",
    "\n",
    "    clf = CatBoostClassifier(**params_frozen)\n",
    "    rs = clf.randomized_search(\n",
    "        params_grid,\n",
    "        train_pool,\n",
    "        n_iter=5,\n",
    "        shuffle=True,\n",
    "        stratified=True,\n",
    "        partition_random_seed=0,\n",
    "        cv=5,\n",
    "        calc_cv_statistics=True,\n",
    "        search_by_train_test_split=False,\n",
    "        refit=True,\n",
    "    )\n",
    "\n",
    "    return clf, df_, X_train, X_test, y_train, y_test, all_features, cat_features, target_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Epoch 1 from 3\n",
      "==================================================\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "0:\tloss: 0.7551082\tbest: 0.7551082 (0)\ttotal: 34.6s\tremaining: 2m 18s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "1:\tloss: 0.8291775\tbest: 0.8291775 (1)\ttotal: 1m 27s\tremaining: 2m 11s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "2:\tloss: 0.7646320\tbest: 0.8291775 (1)\ttotal: 2m 17s\tremaining: 1m 31s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "3:\tloss: 0.7464935\tbest: 0.8291775 (1)\ttotal: 3m 49s\tremaining: 57.5s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "4:\tloss: 0.7456277\tbest: 0.8291775 (1)\ttotal: 5m 25s\tremaining: 0us\n",
      "Accuracy: 0.89\n",
      "F1 Score: 0.92\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.73      0.80        11\n",
      "           1       0.89      0.96      0.92        25\n",
      "\n",
      "    accuracy                           0.89        36\n",
      "   macro avg       0.89      0.84      0.86        36\n",
      "weighted avg       0.89      0.89      0.89        36\n",
      "\n",
      "Fetures to drop\n",
      "['Feature_58', 'Feature_40', 'Feature_51', 'Feature_55', 'Feature_106', 'Feature_60', 'Feature_14', 'Feature_78', 'Feature_38', 'Feature_48', 'Feature_77', 'Feature_67', 'Feature_64', 'Feature_86', 'Feature_65', 'Feature_80', 'Feature_39', 'Feature_66', 'Feature_31', 'Feature_53', 'Feature_62', 'Feature_109', 'Feature_24', 'Feature_59', 'Feature_81', 'Feature_73', 'Feature_43', 'Feature_10', 'Feature_115', 'Feature_72', 'Feature_114', 'Feature_117', 'Feature_79', 'Feature_61', 'Feature_82', 'Feature_92', 'Feature_96', 'Feature_69', 'Feature_84', 'Feature_26', 'Feature_111', 'Feature_7', 'Feature_95', 'Feature_45', 'Feature_74', 'Feature_113', 'Feature_25', 'Feature_112', 'Feature_1', 'Feature_8', 'Feature_91', 'Feature_110', 'Feature_118', 'Feature_107', 'Feature_75', 'Feature_88', 'Feature_27', 'Feature_87', 'Feature_83', 'Feature_50', 'Feature_93', 'Feature_89', 'Feature_85', 'Feature_11', 'Feature_12', 'Feature_13', 'Feature_15', 'Feature_16', 'Feature_19', 'Feature_20', 'Feature_90', 'Feature_21', 'Feature_100', 'Feature_2', 'Feature_76', 'Feature_97', 'Feature_36', 'Feature_98']\n",
      "\n",
      "Epoch 2 from 3\n",
      "==================================================\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "0:\tloss: 0.8214286\tbest: 0.8214286 (0)\ttotal: 17.3s\tremaining: 1m 9s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "1:\tloss: 0.8114286\tbest: 0.8214286 (0)\ttotal: 34.4s\tremaining: 51.5s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "2:\tloss: 0.7841991\tbest: 0.8214286 (0)\ttotal: 51s\tremaining: 34s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "3:\tloss: 0.8128139\tbest: 0.8214286 (0)\ttotal: 1m 26s\tremaining: 21.7s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "4:\tloss: 0.7923810\tbest: 0.8214286 (0)\ttotal: 2m 12s\tremaining: 0us\n",
      "Accuracy: 0.94\n",
      "F1 Score: 0.96\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        11\n",
      "           1       0.93      1.00      0.96        25\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.91      0.93        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "Fetures to drop\n",
      "['Feature_58', 'Feature_40', 'Feature_51', 'Feature_55', 'Feature_106', 'Feature_60', 'Feature_14', 'Feature_78', 'Feature_38', 'Feature_48', 'Feature_77', 'Feature_67', 'Feature_64', 'Feature_86', 'Feature_65', 'Feature_80', 'Feature_39', 'Feature_66', 'Feature_31', 'Feature_53', 'Feature_62', 'Feature_109', 'Feature_24', 'Feature_59', 'Feature_81', 'Feature_73', 'Feature_43', 'Feature_10', 'Feature_115', 'Feature_72', 'Feature_114', 'Feature_117', 'Feature_79', 'Feature_61', 'Feature_82', 'Feature_92', 'Feature_96', 'Feature_69', 'Feature_84', 'Feature_26', 'Feature_111', 'Feature_7', 'Feature_95', 'Feature_45', 'Feature_74', 'Feature_113', 'Feature_25', 'Feature_112', 'Feature_1', 'Feature_8', 'Feature_91', 'Feature_110', 'Feature_118', 'Feature_107', 'Feature_75', 'Feature_88', 'Feature_27', 'Feature_87', 'Feature_83', 'Feature_50', 'Feature_93', 'Feature_89', 'Feature_85', 'Feature_11', 'Feature_12', 'Feature_13', 'Feature_15', 'Feature_16', 'Feature_19', 'Feature_20', 'Feature_90', 'Feature_21', 'Feature_100', 'Feature_2', 'Feature_76', 'Feature_97', 'Feature_36', 'Feature_98', 'Feature_33']\n",
      "\n",
      "Epoch 3 from 3\n",
      "==================================================\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "0:\tloss: 0.8382684\tbest: 0.8382684 (0)\ttotal: 25.1s\tremaining: 1m 40s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "1:\tloss: 0.8477922\tbest: 0.8477922 (1)\ttotal: 1m\tremaining: 1m 31s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "2:\tloss: 0.7928571\tbest: 0.8477922 (1)\ttotal: 1m 21s\tremaining: 54.3s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "3:\tloss: 0.8300866\tbest: 0.8477922 (1)\ttotal: 2m 22s\tremaining: 35.6s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "4:\tloss: 0.8137662\tbest: 0.8477922 (1)\ttotal: 2m 47s\tremaining: 0us\n",
      "Accuracy: 0.86\n",
      "F1 Score: 0.9\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76        11\n",
      "           1       0.88      0.92      0.90        25\n",
      "\n",
      "    accuracy                           0.86        36\n",
      "   macro avg       0.84      0.82      0.83        36\n",
      "weighted avg       0.86      0.86      0.86        36\n",
      "\n",
      "Fetures to drop\n",
      "['Feature_58', 'Feature_40', 'Feature_51', 'Feature_55', 'Feature_106', 'Feature_60', 'Feature_14', 'Feature_78', 'Feature_38', 'Feature_48', 'Feature_77', 'Feature_67', 'Feature_64', 'Feature_86', 'Feature_65', 'Feature_80', 'Feature_39', 'Feature_66', 'Feature_31', 'Feature_53', 'Feature_62', 'Feature_109', 'Feature_24', 'Feature_59', 'Feature_81', 'Feature_73', 'Feature_43', 'Feature_10', 'Feature_115', 'Feature_72', 'Feature_114', 'Feature_117', 'Feature_79', 'Feature_61', 'Feature_82', 'Feature_92', 'Feature_96', 'Feature_69', 'Feature_84', 'Feature_26', 'Feature_111', 'Feature_7', 'Feature_95', 'Feature_45', 'Feature_74', 'Feature_113', 'Feature_25', 'Feature_112', 'Feature_1', 'Feature_8', 'Feature_91', 'Feature_110', 'Feature_118', 'Feature_107', 'Feature_75', 'Feature_88', 'Feature_27', 'Feature_87', 'Feature_83', 'Feature_50', 'Feature_93', 'Feature_89', 'Feature_85', 'Feature_11', 'Feature_12', 'Feature_13', 'Feature_15', 'Feature_16', 'Feature_19', 'Feature_20', 'Feature_90', 'Feature_21', 'Feature_100', 'Feature_2', 'Feature_76', 'Feature_97', 'Feature_36', 'Feature_98', 'Feature_33']\n"
     ]
    }
   ],
   "source": [
    "trash_features = []\n",
    "epochs = 3\n",
    "for epoch in range(1, epochs+1):\n",
    "\n",
    "    print(f\"\\nEpoch {epoch} from {epochs}\\n{'=' * 50}\")\n",
    "\n",
    "    clf, df, X_train, X_test, y_train, y_test, all_features, cat_features, target_feature = train(\n",
    "        df_init,\n",
    "        trash_features=trash_features,\n",
    "        drop_susp_features=True,\n",
    "    )\n",
    "\n",
    "    test_pool = Pool(\n",
    "        X_test,\n",
    "        y_test,\n",
    "        cat_features=cat_features\n",
    "    )\n",
    "    y_test_pred = clf.predict(test_pool)\n",
    "\n",
    "    print(f'Accuracy: {round(accuracy_score(y_test, y_test_pred), 2)}')\n",
    "    print(f'F1 Score: {round(f1_score(y_test, y_test_pred), 2)}')\n",
    "    print(f'\\nClassification report: \\n{classification_report(y_test, y_test_pred)}')\n",
    "\n",
    "    feature_importances = pd.DataFrame(\n",
    "        zip(X_train.columns, clf.get_feature_importance()),\n",
    "        columns=['feature_name', 'importance']\n",
    "    )\n",
    "\n",
    "    feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n",
    "    features = feature_importances[feature_importances['importance'] < 1 ]['feature_name'].tolist()\n",
    "    if len(trash_features) > 0:\n",
    "        for feature in features:\n",
    "            if feature not in trash_features:\n",
    "                trash_features.append(feature)\n",
    "    else:\n",
    "        trash_features=features\n",
    "\n",
    "    print('Fetures to drop')\n",
    "    print(trash_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "0:\tloss: 0.8214286\tbest: 0.8214286 (0)\ttotal: 19.9s\tremaining: 1m 19s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "1:\tloss: 0.8114286\tbest: 0.8214286 (0)\ttotal: 37.5s\tremaining: 56.2s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "2:\tloss: 0.7841991\tbest: 0.8214286 (0)\ttotal: 55s\tremaining: 36.7s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "3:\tloss: 0.8128139\tbest: 0.8214286 (0)\ttotal: 1m 32s\tremaining: 23.1s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "4:\tloss: 0.7923810\tbest: 0.8214286 (0)\ttotal: 2m 18s\tremaining: 0us\n",
      "Accuracy: 0.94\n",
      "F1 Score: 0.96\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        11\n",
      "           1       0.93      1.00      0.96        25\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.91      0.93        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trash_features = ['Feature_58', 'Feature_40', 'Feature_51', 'Feature_55', 'Feature_106', 'Feature_60', 'Feature_14', 'Feature_78', 'Feature_38', \n",
    "                    'Feature_48', 'Feature_77', 'Feature_67', 'Feature_64', 'Feature_86', 'Feature_65', 'Feature_80', 'Feature_39', 'Feature_66', 'Feature_31', \n",
    "                    'Feature_53', 'Feature_62', 'Feature_109', 'Feature_24', 'Feature_59', 'Feature_81', 'Feature_73', 'Feature_43', 'Feature_10', 'Feature_115', \n",
    "                    'Feature_72', 'Feature_114', 'Feature_117', 'Feature_79', 'Feature_61', 'Feature_82', 'Feature_92', 'Feature_96', 'Feature_69', 'Feature_84', \n",
    "                    'Feature_26', 'Feature_111', 'Feature_7', 'Feature_95', 'Feature_45', 'Feature_74', 'Feature_113', 'Feature_25', 'Feature_112', 'Feature_1',\n",
    "                     'Feature_8', 'Feature_91', 'Feature_110', 'Feature_118', 'Feature_107', 'Feature_75', 'Feature_88', 'Feature_27', 'Feature_87', 'Feature_83', \n",
    "                     'Feature_50', 'Feature_93', 'Feature_89', 'Feature_85', 'Feature_11', 'Feature_12', 'Feature_13', 'Feature_15', 'Feature_16', 'Feature_19', \n",
    "                     'Feature_20', 'Feature_90', 'Feature_21', 'Feature_100', 'Feature_2', 'Feature_76', 'Feature_97', 'Feature_36', 'Feature_98']\n",
    "\n",
    "clf, df, X_train, X_test, y_train, y_test, all_features, cat_features, target_feature = train(\n",
    "    df_init,\n",
    "    trash_features=trash_features,\n",
    "    drop_susp_features=True,\n",
    ")\n",
    "\n",
    "test_pool = Pool(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    cat_features=cat_features\n",
    ")\n",
    "y_test_pred = clf.predict(test_pool)\n",
    "\n",
    "print(f'Accuracy: {round(accuracy_score(y_test, y_test_pred), 2)}')\n",
    "print(f'F1 Score: {round(f1_score(y_test, y_test_pred), 2)}')\n",
    "print(f'\\nClassification report: \\n{classification_report(y_test, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   feature_name  importance\n",
       "5    Feature_34   10.617119\n",
       "7    Feature_41    9.879993\n",
       "14   Feature_56    8.034348\n",
       "18   Feature_70    6.981418\n",
       "0     Feature_5    5.418372\n",
       "6    Feature_37    5.186738\n",
       "1     Feature_6    5.087225\n",
       "20   Feature_99    4.954018\n",
       "3    Feature_28    4.933184\n",
       "19   Feature_71    4.268971\n",
       "11   Feature_47    4.196597\n",
       "17   Feature_68    4.084753\n",
       "10   Feature_46    3.966846\n",
       "2     Feature_9    3.184563\n",
       "9    Feature_44    3.147187\n",
       "21  Feature_116    2.911937\n",
       "12   Feature_49    2.813573\n",
       "16   Feature_63    2.516897\n",
       "15   Feature_57    2.509772\n",
       "8    Feature_42    2.419652\n",
       "13   Feature_52    2.241058\n",
       "4    Feature_33    0.645777"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_name</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>Feature_34</td>\n      <td>10.617119</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Feature_41</td>\n      <td>9.879993</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Feature_56</td>\n      <td>8.034348</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Feature_70</td>\n      <td>6.981418</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature_5</td>\n      <td>5.418372</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Feature_37</td>\n      <td>5.186738</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Feature_6</td>\n      <td>5.087225</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Feature_99</td>\n      <td>4.954018</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Feature_28</td>\n      <td>4.933184</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Feature_71</td>\n      <td>4.268971</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Feature_47</td>\n      <td>4.196597</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Feature_68</td>\n      <td>4.084753</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Feature_46</td>\n      <td>3.966846</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Feature_9</td>\n      <td>3.184563</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Feature_44</td>\n      <td>3.147187</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Feature_116</td>\n      <td>2.911937</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Feature_49</td>\n      <td>2.813573</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Feature_63</td>\n      <td>2.516897</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Feature_57</td>\n      <td>2.509772</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Feature_42</td>\n      <td>2.419652</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Feature_52</td>\n      <td>2.241058</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Feature_33</td>\n      <td>0.645777</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(\n",
    "    zip(X_train.columns, clf.get_feature_importance()),\n",
    "    columns=['feature_name', 'importance']\n",
    ")\n",
    "\n",
    "feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n",
    "feature_importances.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37764bit3fbe5ae206bf467f9f636d844c57ff6e",
   "display_name": "Python 3.7.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "ca35beca1e73f0e8e48de5d26c91c8a581bc78491f6978c6ebd776970508bb03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}