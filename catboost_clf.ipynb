{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Id  Result  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  \\\n",
       "0   1       2          2         56         12          1        7.0   \n",
       "1   2       2          2         69         19          1        6.0   \n",
       "2   3       2          1         66          8          1        4.0   \n",
       "3   4       2          2         62         16          1        NaN   \n",
       "4   5       2          2         67         30          1        NaN   \n",
       "\n",
       "   Feature_6  Feature_7  Feature_8  ...  Feature_109  Feature_110  \\\n",
       "0          4          0        1.0  ...          1.0          0.0   \n",
       "1          4          0        1.0  ...          1.0          0.0   \n",
       "2          4          0        1.0  ...          1.0          0.0   \n",
       "3          3          0        1.0  ...          1.0          0.0   \n",
       "4          4          0        1.0  ...          1.0          0.0   \n",
       "\n",
       "   Feature_111  Feature_112  Feature_113  Feature_114  Feature_115  \\\n",
       "0            1            0            1            1            1   \n",
       "1            1            0            1            1            1   \n",
       "2            1            0            1            1            1   \n",
       "3            1            0            1            1            0   \n",
       "4            1            0            1            1            1   \n",
       "\n",
       "   Feature_116  Feature_117  Feature_118  \n",
       "0            1            1            0  \n",
       "1            0            1            1  \n",
       "2            0            1            0  \n",
       "3            0            1            1  \n",
       "4            0            1            0  \n",
       "\n",
       "[5 rows x 116 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Result</th>\n      <th>Feature_1</th>\n      <th>Feature_2</th>\n      <th>Feature_3</th>\n      <th>Feature_4</th>\n      <th>Feature_5</th>\n      <th>Feature_6</th>\n      <th>Feature_7</th>\n      <th>Feature_8</th>\n      <th>...</th>\n      <th>Feature_109</th>\n      <th>Feature_110</th>\n      <th>Feature_111</th>\n      <th>Feature_112</th>\n      <th>Feature_113</th>\n      <th>Feature_114</th>\n      <th>Feature_115</th>\n      <th>Feature_116</th>\n      <th>Feature_117</th>\n      <th>Feature_118</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>56</td>\n      <td>12</td>\n      <td>1</td>\n      <td>7.0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>69</td>\n      <td>19</td>\n      <td>1</td>\n      <td>6.0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>66</td>\n      <td>8</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>62</td>\n      <td>16</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2</td>\n      <td>2</td>\n      <td>67</td>\n      <td>30</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 116 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df_init = pd.read_csv('data.csv', sep=';')\n",
    "df_init.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Epoch 1 from 3\n",
      "==================================================\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "0:\tloss: 0.8052308\tbest: 0.8052308 (0)\ttotal: 57.8s\tremaining: 3m 51s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "1:\tloss: 0.8283077\tbest: 0.8283077 (1)\ttotal: 2m 4s\tremaining: 3m 6s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "2:\tloss: 0.8440000\tbest: 0.8440000 (2)\ttotal: 2m 37s\tremaining: 1m 44s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "3:\tloss: 0.8123077\tbest: 0.8440000 (2)\ttotal: 3m 50s\tremaining: 57.6s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "4:\tloss: 0.8129231\tbest: 0.8440000 (2)\ttotal: 5m 21s\tremaining: 0us\n",
      "Accuracy: 0.93\n",
      "F1 Score: 0.89\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.95      0.90      0.92        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "Fetures to drop\n",
      "['Feature_90', 'Feature_100', 'Feature_65', 'Feature_116', 'Feature_93', 'Feature_40', 'Feature_46', 'Feature_68', 'Feature_79', 'Feature_44', 'Feature_80', 'Feature_53', 'Feature_39', 'Feature_50', 'Feature_8', 'Feature_67', 'Feature_60', 'Feature_96', 'Feature_22', 'Feature_75', 'Feature_77', 'Feature_84', 'Feature_45', 'Feature_73', 'Feature_43', 'Feature_83', 'Feature_114', 'Feature_14', 'Feature_89', 'Feature_52', 'Feature_71', 'Feature_10', 'Feature_51', 'Feature_28', 'Feature_11', 'Feature_112', 'Feature_106', 'Feature_42', 'Feature_87', 'Feature_82', 'Feature_21', 'Feature_118', 'Feature_48', 'Feature_74', 'Feature_12', 'Feature_98', 'Feature_72', 'Feature_117', 'Feature_107', 'Feature_38', 'Feature_111', 'Feature_55', 'Feature_92', 'Feature_24', 'Feature_113', 'Feature_91', 'Feature_86', 'Feature_95', 'Feature_7', 'Feature_31', 'Feature_15', 'Feature_63', 'Feature_76', 'Feature_78', 'Feature_62', 'Feature_97', 'Feature_13', 'Feature_61', 'Feature_115', 'Feature_110', 'Feature_26', 'Feature_16', 'Feature_19', 'Feature_20', 'Feature_25', 'Feature_27', 'Feature_36', 'Feature_37', 'Feature_2', 'Feature_66', 'Feature_1']\n",
      "\n",
      "Epoch 2 from 3\n",
      "==================================================\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "0:\tloss: 0.8596923\tbest: 0.8596923 (0)\ttotal: 33.6s\tremaining: 2m 14s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "1:\tloss: 0.8436923\tbest: 0.8596923 (0)\ttotal: 49.2s\tremaining: 1m 13s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "2:\tloss: 0.8436923\tbest: 0.8596923 (0)\ttotal: 1m 11s\tremaining: 47.6s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "3:\tloss: 0.8676923\tbest: 0.8676923 (3)\ttotal: 2m 17s\tremaining: 34.4s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "4:\tloss: 0.8283077\tbest: 0.8676923 (3)\ttotal: 2m 59s\tremaining: 0us\n",
      "Accuracy: 0.87\n",
      "F1 Score: 0.8\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        10\n",
      "           1       0.80      0.80      0.80         5\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.85      0.85      0.85        15\n",
      "weighted avg       0.87      0.87      0.87        15\n",
      "\n",
      "Fetures to drop\n",
      "['Feature_90', 'Feature_100', 'Feature_65', 'Feature_116', 'Feature_93', 'Feature_40', 'Feature_46', 'Feature_68', 'Feature_79', 'Feature_44', 'Feature_80', 'Feature_53', 'Feature_39', 'Feature_50', 'Feature_8', 'Feature_67', 'Feature_60', 'Feature_96', 'Feature_22', 'Feature_75', 'Feature_77', 'Feature_84', 'Feature_45', 'Feature_73', 'Feature_43', 'Feature_83', 'Feature_114', 'Feature_14', 'Feature_89', 'Feature_52', 'Feature_71', 'Feature_10', 'Feature_51', 'Feature_28', 'Feature_11', 'Feature_112', 'Feature_106', 'Feature_42', 'Feature_87', 'Feature_82', 'Feature_21', 'Feature_118', 'Feature_48', 'Feature_74', 'Feature_12', 'Feature_98', 'Feature_72', 'Feature_117', 'Feature_107', 'Feature_38', 'Feature_111', 'Feature_55', 'Feature_92', 'Feature_24', 'Feature_113', 'Feature_91', 'Feature_86', 'Feature_95', 'Feature_7', 'Feature_31', 'Feature_15', 'Feature_63', 'Feature_76', 'Feature_78', 'Feature_62', 'Feature_97', 'Feature_13', 'Feature_61', 'Feature_115', 'Feature_110', 'Feature_26', 'Feature_16', 'Feature_19', 'Feature_20', 'Feature_25', 'Feature_27', 'Feature_36', 'Feature_37', 'Feature_2', 'Feature_66', 'Feature_1', 'Feature_85', 'Feature_54', 'Feature_64', 'Feature_58', 'Feature_34']\n",
      "\n",
      "Epoch 3 from 3\n",
      "==================================================\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "0:\tloss: 0.8603077\tbest: 0.8603077 (0)\ttotal: 41.6s\tremaining: 2m 46s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "1:\tloss: 0.8600000\tbest: 0.8603077 (0)\ttotal: 1m 16s\tremaining: 1m 55s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "2:\tloss: 0.8683077\tbest: 0.8683077 (2)\ttotal: 1m 35s\tremaining: 1m 3s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "3:\tloss: 0.8523077\tbest: 0.8683077 (2)\ttotal: 2m 45s\tremaining: 41.5s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "4:\tloss: 0.8286154\tbest: 0.8683077 (2)\ttotal: 3m 22s\tremaining: 0us\n",
      "Accuracy: 0.87\n",
      "F1 Score: 0.8\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        10\n",
      "           1       0.80      0.80      0.80         5\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.85      0.85      0.85        15\n",
      "weighted avg       0.87      0.87      0.87        15\n",
      "\n",
      "Fetures to drop\n",
      "['Feature_90', 'Feature_100', 'Feature_65', 'Feature_116', 'Feature_93', 'Feature_40', 'Feature_46', 'Feature_68', 'Feature_79', 'Feature_44', 'Feature_80', 'Feature_53', 'Feature_39', 'Feature_50', 'Feature_8', 'Feature_67', 'Feature_60', 'Feature_96', 'Feature_22', 'Feature_75', 'Feature_77', 'Feature_84', 'Feature_45', 'Feature_73', 'Feature_43', 'Feature_83', 'Feature_114', 'Feature_14', 'Feature_89', 'Feature_52', 'Feature_71', 'Feature_10', 'Feature_51', 'Feature_28', 'Feature_11', 'Feature_112', 'Feature_106', 'Feature_42', 'Feature_87', 'Feature_82', 'Feature_21', 'Feature_118', 'Feature_48', 'Feature_74', 'Feature_12', 'Feature_98', 'Feature_72', 'Feature_117', 'Feature_107', 'Feature_38', 'Feature_111', 'Feature_55', 'Feature_92', 'Feature_24', 'Feature_113', 'Feature_91', 'Feature_86', 'Feature_95', 'Feature_7', 'Feature_31', 'Feature_15', 'Feature_63', 'Feature_76', 'Feature_78', 'Feature_62', 'Feature_97', 'Feature_13', 'Feature_61', 'Feature_115', 'Feature_110', 'Feature_26', 'Feature_16', 'Feature_19', 'Feature_20', 'Feature_25', 'Feature_27', 'Feature_36', 'Feature_37', 'Feature_2', 'Feature_66', 'Feature_1', 'Feature_85', 'Feature_54', 'Feature_64', 'Feature_58', 'Feature_34', 'Feature_88', 'Feature_81']\n"
     ]
    }
   ],
   "source": [
    "def train(df, trash_features = [], drop_susp_features = True):\n",
    "\n",
    "    df_ = df.copy()\n",
    "\n",
    "    target_feature = 'Result'\n",
    "    golden_features = ['Feature_3', 'Feature_4', 'Feature_35']\n",
    "    susp_features = ['Feature_29', 'Feature_30', 'Feature_32', 'Feature_101'] if drop_susp_features else []\n",
    "    all_features = df_.columns.drop([target_feature] + golden_features + susp_features + trash_features + ['Id']).tolist()\n",
    "\n",
    "    df_ = df_[[target_feature] + all_features]\n",
    "\n",
    "    num_features = ['Feature_39', 'Feature_40', 'Feature_41', 'Feature_42', 'Feature_43', 'Feature_44', 'Feature_45', 'Feature_46',\n",
    "                'Feature_47', 'Feature_48', 'Feature_49', 'Feature_50', 'Feature_51', 'Feature_53', 'Feature_55', 'Feature_57', \n",
    "                'Feature_58', 'Feature_59', 'Feature_64', 'Feature_70', 'Feature_71', 'Feature_72', 'Feature_73']\n",
    "    cat_features = []\n",
    "\n",
    "    for col in df_.drop(target_feature, axis=1).columns:\n",
    "        if col in num_features:\n",
    "            df_[col].fillna(df_[col].median(), inplace=True)\n",
    "            df_[col] = df_[col].astype('float64')\n",
    "        else:\n",
    "            cat_features.append(col)\n",
    "\n",
    "            df_[col].fillna(-1, inplace=True)\n",
    "            df_[col] = df_[col].astype('int64')\n",
    "    \n",
    "    # Result=0 - alive, Result=1 died\n",
    "    df_.loc[df_[target_feature] == 1, target_feature] = 1\n",
    "    df_.loc[df_[target_feature] == 2, target_feature] = 0\n",
    "\n",
    "    X = df_[all_features]\n",
    "    y = df_[target_feature]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        shuffle=True,\n",
    "        test_size=0.1,\n",
    "        random_state=0,\n",
    "        stratify=y,\n",
    "    )\n",
    "\n",
    "    train_pool = Pool(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cat_features=cat_features\n",
    "    )\n",
    "\n",
    "    params_frozen = {\n",
    "        'eval_metric': 'Accuracy',\n",
    "        'early_stopping_rounds': 50,\n",
    "    }\n",
    "\n",
    "    params_grid = {\n",
    "        'depth': [4, 6, 8, 10],\n",
    "        'learning_rate': [0.03, 0.1, 0.3, 0.5],\n",
    "        'iterations': [100, 200, 400, 600, 800, 1000, 1200],\n",
    "        'l2_leaf_reg': [2, 2.5, 3, 3.5, 4],\n",
    "        'bagging_temperature': [1, 1.5, 2, 2.5],\n",
    "    }\n",
    "\n",
    "    clf = CatBoostClassifier(**params_frozen)\n",
    "    rs = clf.randomized_search(\n",
    "        params_grid,\n",
    "        train_pool,\n",
    "        n_iter=5,\n",
    "        shuffle=True,\n",
    "        stratified=True,\n",
    "        partition_random_seed=0,\n",
    "        cv=5,\n",
    "        calc_cv_statistics=True,\n",
    "        search_by_train_test_split=False,\n",
    "        refit=True,\n",
    "    )\n",
    "\n",
    "    return clf, df_, X_train, X_test, y_train, y_test, all_features, cat_features, target_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trash_features = []\n",
    "epochs = 3\n",
    "for epoch in range(1, epochs+1):\n",
    "\n",
    "    print(f\"\\nEpoch {epoch} from {epochs}\\n{'=' * 50}\")\n",
    "\n",
    "    clf, df, X_train, X_test, y_train, y_test, all_features, cat_features, target_feature = train(\n",
    "        df_init,\n",
    "        trash_features=trash_features,\n",
    "        drop_susp_features=True,\n",
    "    )\n",
    "\n",
    "    test_pool = Pool(\n",
    "        X_test,\n",
    "        y_test,\n",
    "        cat_features=cat_features\n",
    "    )\n",
    "    y_test_pred = clf.predict(test_pool)\n",
    "\n",
    "    print(f'Accuracy: {round(accuracy_score(y_test, y_test_pred), 2)}')\n",
    "    print(f'F1 Score: {round(f1_score(y_test, y_test_pred), 2)}')\n",
    "    print(f'\\nClassification report: \\n{classification_report(y_test, y_test_pred)}')\n",
    "\n",
    "    feature_importances = pd.DataFrame(\n",
    "        zip(X_train.columns, clf.get_feature_importance()),\n",
    "        columns=['feature_name', 'importance']\n",
    "    )\n",
    "\n",
    "    feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n",
    "    features = feature_importances[feature_importances['importance'] < 1 ]['feature_name'].tolist()\n",
    "    if len(trash_features) > 0:\n",
    "        for feature in features:\n",
    "            if feature not in trash_features:\n",
    "                trash_features.append(feature)\n",
    "    else:\n",
    "        trash_features=features\n",
    "\n",
    "    print('Fetures to drop')\n",
    "    print(trash_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "0:\tloss: 0.8516923\tbest: 0.8516923 (0)\ttotal: 41.2s\tremaining: 2m 44s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "1:\tloss: 0.8443077\tbest: 0.8516923 (0)\ttotal: 1m 8s\tremaining: 1m 43s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "2:\tloss: 0.8363077\tbest: 0.8516923 (0)\ttotal: 1m 24s\tremaining: 56.2s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "3:\tloss: 0.8363077\tbest: 0.8516923 (0)\ttotal: 1m 56s\tremaining: 29.2s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "4:\tloss: 0.8440000\tbest: 0.8516923 (0)\ttotal: 2m 28s\tremaining: 0us\n",
      "Accuracy: 0.87\n",
      "F1 Score: 0.8\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        10\n",
      "           1       0.80      0.80      0.80         5\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.85      0.85      0.85        15\n",
      "weighted avg       0.87      0.87      0.87        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trash_features = ['Feature_90', 'Feature_100', 'Feature_65', 'Feature_116', 'Feature_93', 'Feature_40', 'Feature_46',\n",
    "                'Feature_68', 'Feature_79', 'Feature_44', 'Feature_80', 'Feature_53', 'Feature_39', 'Feature_50', 'Feature_8',\n",
    "                'Feature_67', 'Feature_60', 'Feature_96', 'Feature_22', 'Feature_75', 'Feature_77', 'Feature_84', 'Feature_45',\n",
    "                'Feature_73', 'Feature_43', 'Feature_83', 'Feature_114', 'Feature_14', 'Feature_89', 'Feature_52', 'Feature_71',\n",
    "                'Feature_10', 'Feature_51', 'Feature_28', 'Feature_11', 'Feature_112', 'Feature_106', 'Feature_42', 'Feature_87',\n",
    "                'Feature_82', 'Feature_21', 'Feature_118', 'Feature_48', 'Feature_74', 'Feature_12', 'Feature_98', 'Feature_72',\n",
    "                'Feature_117', 'Feature_107', 'Feature_38', 'Feature_111', 'Feature_55', 'Feature_92', 'Feature_24', 'Feature_113',\n",
    "                'Feature_91', 'Feature_86', 'Feature_95', 'Feature_7', 'Feature_31', 'Feature_15', 'Feature_63', 'Feature_76',\n",
    "                'Feature_78', 'Feature_62', 'Feature_97', 'Feature_13', 'Feature_61', 'Feature_115', 'Feature_110', 'Feature_26', \n",
    "                'Feature_16', 'Feature_19', 'Feature_20', 'Feature_25', 'Feature_27', 'Feature_36', 'Feature_37', 'Feature_2', \n",
    "                'Feature_66', 'Feature_1', 'Feature_85', 'Feature_54', 'Feature_64', 'Feature_58', 'Feature_34', 'Feature_88', 'Feature_81']\n",
    "\n",
    "clf, df, X_train, X_test, y_train, y_test, all_features, cat_features, target_feature = train(\n",
    "    df_init,\n",
    "    trash_features=trash_features,\n",
    "    drop_susp_features=True,\n",
    ")\n",
    "\n",
    "test_pool = Pool(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    cat_features=cat_features\n",
    ")\n",
    "y_test_pred = clf.predict(test_pool)\n",
    "\n",
    "print(f'Accuracy: {round(accuracy_score(y_test, y_test_pred), 2)}')\n",
    "print(f'F1 Score: {round(f1_score(y_test, y_test_pred), 2)}')\n",
    "print(f'\\nClassification report: \\n{classification_report(y_test, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   feature_name  importance\n",
       "4    Feature_18   17.177368\n",
       "17  Feature_108    9.775050\n",
       "7    Feature_41    8.826360\n",
       "2     Feature_9    8.349722\n",
       "5    Feature_23    8.048525\n",
       "10   Feature_56    7.610637\n",
       "14   Feature_70    5.624118\n",
       "1     Feature_6    5.487453\n",
       "8    Feature_47    5.226363\n",
       "16   Feature_99    4.559015\n",
       "15   Feature_94    4.362810\n",
       "11   Feature_57    4.200641\n",
       "18  Feature_109    3.288556\n",
       "12   Feature_59    2.740524\n",
       "9    Feature_49    1.935554\n",
       "13   Feature_69    1.289075\n",
       "3    Feature_17    1.140559\n",
       "6    Feature_33    0.182810\n",
       "0     Feature_5    0.174861"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_name</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>Feature_18</td>\n      <td>17.177368</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Feature_108</td>\n      <td>9.775050</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Feature_41</td>\n      <td>8.826360</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Feature_9</td>\n      <td>8.349722</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Feature_23</td>\n      <td>8.048525</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Feature_56</td>\n      <td>7.610637</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Feature_70</td>\n      <td>5.624118</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Feature_6</td>\n      <td>5.487453</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Feature_47</td>\n      <td>5.226363</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Feature_99</td>\n      <td>4.559015</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Feature_94</td>\n      <td>4.362810</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Feature_57</td>\n      <td>4.200641</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Feature_109</td>\n      <td>3.288556</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Feature_59</td>\n      <td>2.740524</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Feature_49</td>\n      <td>1.935554</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Feature_69</td>\n      <td>1.289075</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Feature_17</td>\n      <td>1.140559</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Feature_33</td>\n      <td>0.182810</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature_5</td>\n      <td>0.174861</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(\n",
    "    zip(X_train.columns, clf.get_feature_importance()),\n",
    "    columns=['feature_name', 'importance']\n",
    ")\n",
    "\n",
    "feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n",
    "feature_importances.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37764bit3fbe5ae206bf467f9f636d844c57ff6e",
   "display_name": "Python 3.7.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "ca35beca1e73f0e8e48de5d26c91c8a581bc78491f6978c6ebd776970508bb03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}